{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/johnobodai/alu-machine_learning/blob/main/ML_SUMMATIVE_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukjfUvNZe1vE"
   },
   "source": [
    "# **Import Libraries and Load Data**\n",
    "*Imports necessary libraries for data preprocessing and model training. It also loads the Kaggle dataset from Google Drive.[dataset.cvs](https://docs.google.com/spreadsheets/d/15CsEhLuLZEKHGW2YCpQXikyJntFxV7U9rgNJl4asFWM/edit?usp=sharing)*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vVRN5ZCWW9a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Load Kaggle dataset from Google Drive\n",
    "kaggle_data_link = 'https://drive.google.com/uc?id=1joIqVz1UYhiIJX590sjAR7cE-Sk6-G_Y'\n",
    "kaggle_data = pd.read_csv(kaggle_data_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BzFDjhDfGyG"
   },
   "source": [
    "# Data Preprocessing\n",
    "*Handles data preprocessing tasks such as filling missing values and converting categorical data into numerical format. It also prepares the dataset for further analysis by separating features and the target variable ('Target_Dropout').*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkOzSSc7XirA",
    "outputId": "da4710b4-2817-4671-8f07-6c0f4d126867"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in numeric columns with mean\n",
    "numeric_columns = kaggle_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "kaggle_data[numeric_columns] = kaggle_data[numeric_columns].fillna(kaggle_data[numeric_columns].mean())\n",
    "\n",
    "# Fill missing values in categorical columns with mode\n",
    "categorical_columns = kaggle_data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    kaggle_data[column].fillna(kaggle_data[column].mode()[0], inplace=True)\n",
    "\n",
    "# Convert categorical data to numerical using one-hot encoding\n",
    "kaggle_data = pd.get_dummies(kaggle_data)\n",
    "\n",
    "# Set 'Target_Dropout' as the target column\n",
    "target_column = 'Target_Dropout'\n",
    "\n",
    "# Separate features and target\n",
    "X = kaggle_data.drop(columns=['Target_Dropout', 'Target_Enrolled', 'Target_Graduate'])\n",
    "y = kaggle_data[target_column]\n",
    "\n",
    "# Check the distribution of the target variable\n",
    "print(\"Target Variable Distribution:\\n\", y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiiIBgNZfTCq"
   },
   "source": [
    "# Data Scaling and Splitting\n",
    "*Splits the dataset into training and testing sets to prepare for model training and evaluation.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9-qnH47eWPF"
   },
   "outputs": [],
   "source": [
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BUZa7V-1faPF"
   },
   "source": [
    "# Training and Evaluating Models\n",
    "*Trains three different machine learning models: Logistic Regression, Decision Tree Classifier, and Neural Network (MLPClassifier). Each model is fitted using the training data prepared in the previous cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTsE3plseawc",
    "outputId": "b1f9f4d8-0d8d-4799-9926-982c8d90e563"
   },
   "outputs": [],
   "source": [
    "# Train Logistic Regression model with regularization (L2 by default)\n",
    "print(\"Training Logistic Regression model...\")\n",
    "lr = LogisticRegression(C=1.0)  # Set C parameter for regularization strength (adjust as needed)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Train Decision Tree model\n",
    "print(\"Training Decision Tree model...\")\n",
    "dt = DecisionTreeClassifier(max_depth=None, min_samples_split=2)  # Set max_depth and min_samples_split (adjust as needed)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Train Neural Network model with optimizations\n",
    "print(\"Training Neural Network model...\")\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, alpha=0.0001, learning_rate_init=0.001,\n",
    "                  early_stopping=True, validation_fraction=0.1)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Save models\n",
    "dump(lr, 'logistic_regression_model.joblib')\n",
    "dump(dt, 'decision_tree_model.joblib')\n",
    "dump(nn, 'neural_network_model.joblib')\n",
    "\n",
    "# Load models\n",
    "lr_saved = load('logistic_regression_model.joblib')\n",
    "dt_saved = load('decision_tree_model.joblib')\n",
    "nn_saved = load('neural_network_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6yPC3IyfjsU"
   },
   "source": [
    "# Evaluating Models and Analysis\n",
    "*This cell evaluates the performance of each trained model on the test set. It calculates accuracy scores and generates classification reports to assess how well each model predicts the target variable ('Target_Dropout').*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q3teDRpglSWt",
    "outputId": "f6b53302-6ad3-4823-a027-d6fb2cc22091"
   },
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "print(\"\\nEvaluating Logistic Regression:\")\n",
    "print(\"--------------------------------\")\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Calculate Specificity for Logistic Regression\n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "specificity_lr = tn_lr / (tn_lr + fp_lr)\n",
    "print(f\"\\nSpecificity (Logistic Regression): {specificity_lr:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Logistic Regression\n",
    "print(\"\\nConfusion Matrix (Logistic Regression):\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# F1 Score for Logistic Regression\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(f\"\\nF1 Score (Logistic Regression): {f1_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjDEgxYTvFy2",
    "outputId": "7217cf41-8ac3-4fc7-c9fd-4fbbd57c4baa"
   },
   "outputs": [],
   "source": [
    "# Evaluate Decision Tree\n",
    "print(\"\\nEvaluating Decision Tree:\")\n",
    "print(\"--------------------------\")\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "\n",
    "# Calculate Specificity for Decision Tree\n",
    "tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(y_test, y_pred_dt).ravel()\n",
    "specificity_dt = tn_dt / (tn_dt + fp_dt)\n",
    "print(f\"\\nSpecificity (Decision Tree): {specificity_dt:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Decision Tree\n",
    "print(\"\\nConfusion Matrix (Decision Tree):\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# F1 Score for Decision Tree\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "print(f\"\\nF1 Score (Decision Tree): {f1_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "euuAGG7EvH1c",
    "outputId": "168fd7f2-fd7e-4164-a100-4c71bb367add"
   },
   "outputs": [],
   "source": [
    "# Evaluate Neural Network\n",
    "print(\"\\nEvaluating Neural Network:\")\n",
    "print(\"---------------------------\")\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "\n",
    "# Calculate Specificity for Neural Network\n",
    "tn_nn, fp_nn, fn_nn, tp_nn = confusion_matrix(y_test, y_pred_nn).ravel()\n",
    "specificity_nn = tn_nn / (tn_nn + fp_nn)\n",
    "print(f\"\\nSpecificity (Neural Network): {specificity_nn:.4f}\")\n",
    "\n",
    "# Confusion Matrix for Neural Network\n",
    "print(\"\\nConfusion Matrix (Neural Network):\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n",
    "\n",
    "# F1 Score for Neural Network\n",
    "f1_nn = f1_score(y_test, y_pred_nn)\n",
    "print(f\"\\nF1 Score (Neural Network): {f1_nn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24q4ipRmfo9Q"
   },
   "source": [
    "# Feature Importance and Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBU_WWyLiU9N"
   },
   "source": [
    "*Analyzes and prints the feature importance for the Decision Tree model and the coefficients for the Logistic Regression model. Understanding feature importance helps in identifying which features have the most significant impact on predicting the target variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5or4IVLEkjMa",
    "outputId": "fb9ae8d5-7f78-47f4-a7a7-0fde30658617"
   },
   "outputs": [],
   "source": [
    "# Feature importance for Decision Tree\n",
    "print(\"\\nFeature Importance (Decision Tree):\")\n",
    "print(\"------------------------------------\")\n",
    "feature_importance = dt.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
    "importance_df_sorted = importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "print(importance_df_sorted.to_string(index=False))\n",
    "\n",
    "# Coefficients for Logistic Regression\n",
    "print(\"\\nCoefficients (Logistic Regression):\")\n",
    "print(\"-------------------------------------\")\n",
    "coefficients = lr.coef_[0]\n",
    "coef_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})\n",
    "coef_df_sorted = coef_df.reindex(coef_df['Coefficient'].abs().sort_values(ascending=False).index).reset_index(drop=True)\n",
    "print(coef_df_sorted.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2GtNv7ViaZG"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "837CYxSMimT2"
   },
   "source": [
    "#Early Intervention System\n",
    "*Defines an early intervention system function that identifies at-risk students based on predicted probabilities from each model. It demonstrates how to apply the function to the predictions of each model (Logistic Regression, Decision Tree, Neural Network).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXSVAXFEerpM",
    "outputId": "06a0ca2a-2c5d-4c4e-d895-19a8862fbf8c"
   },
   "outputs": [],
   "source": [
    "# Early intervention system\n",
    "def early_intervention(predictions, threshold=0.5):\n",
    "    \"\"\"Identifies at-risk students based on predicted probabilities.\"\"\"\n",
    "    return predictions > threshold\n",
    "\n",
    "# Example usage for Logistic Regression\n",
    "at_risk_lr = early_intervention(lr.predict_proba(X_test)[:, 1])\n",
    "at_risk_dt = early_intervention(dt.predict_proba(X_test)[:, 1])\n",
    "at_risk_nn = early_intervention(nn.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Create a DataFrame to organize results\n",
    "results_df = pd.DataFrame({\n",
    "    'Logistic Regression': at_risk_lr.astype(int),\n",
    "    'Decision Tree': at_risk_dt.astype(int),\n",
    "    'Neural Network': at_risk_nn.astype(int)\n",
    "})\n",
    "\n",
    "# Print formatted results\n",
    "print(\"\\nImplementing Early Intervention System:\")\n",
    "print(\"========================================\\n\")\n",
    "print(\"--------------\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plCE8HzAtGlF"
   },
   "source": [
    "# Error Analysis Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zWcxNubwkU4W",
    "outputId": "5d427c3c-40ac-4333-f9ac-7d39ade6e78b"
   },
   "outputs": [],
   "source": [
    "# Calculate Specificity for Logistic Regression\n",
    "tn_lr, fp_lr, fn_lr, tp_lr = confusion_matrix(y_test, y_pred_lr).ravel()\n",
    "specificity_lr = tn_lr / (tn_lr + fp_lr)\n",
    "print(f\"Specificity (Logistic Regression): {specificity_lr:.4f}\")\n",
    "\n",
    "# Calculate Specificity for Decision Tree\n",
    "tn_dt, fp_dt, fn_dt, tp_dt = confusion_matrix(y_test, y_pred_dt).ravel()\n",
    "specificity_dt = tn_dt / (tn_dt + fp_dt)\n",
    "print(f\"Specificity (Decision Tree): {specificity_dt:.4f}\")\n",
    "\n",
    "# Calculate Specificity for Neural Network\n",
    "tn_nn, fp_nn, fn_nn, tp_nn = confusion_matrix(y_test, y_pred_nn).ravel()\n",
    "specificity_nn = tn_nn / (tn_nn + fp_nn)\n",
    "print(f\"Specificity (Neural Network): {specificity_nn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdTfo3bFstjX",
    "outputId": "95c2f9b8-ffd4-46b8-8af0-81cb7d1ce0c3"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix for Logistic Regression\n",
    "print(\"\\nConfusion Matrix (Logistic Regression):\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "\n",
    "# Confusion Matrix for Decision Tree\n",
    "print(\"\\nConfusion Matrix (Decision Tree):\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n",
    "\n",
    "# Confusion Matrix for Neural Network\n",
    "print(\"\\nConfusion Matrix (Neural Network):\")\n",
    "print(confusion_matrix(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h2SjATWstUa_",
    "outputId": "78e974a9-e8f6-4b23-f9da-1e598ac3866f"
   },
   "outputs": [],
   "source": [
    "# F1 Score for Logistic Regression\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "print(f\"\\nF1 Score (Logistic Regression): {f1_lr:.4f}\")\n",
    "\n",
    "# F1 Score for Decision Tree\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "print(f\"F1 Score (Decision Tree): {f1_dt:.4f}\")\n",
    "\n",
    "# F1 Score for Neural Network\n",
    "f1_nn = f1_score(y_test, y_pred_nn)\n",
    "print(f\"F1 Score (Neural Network): {f1_nn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ab9ehNXvtYl2",
    "outputId": "8e1c9283-5052-4725-b79b-cf26ae4b19c3"
   },
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression (Simple Model)\n",
    "print(\"\\nEvaluating Logistic Regression (Simple Model):\")\n",
    "print(\"----------------------------------------------\")\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "simple_lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy: {simple_lr_accuracy:.4f}\")\n",
    "\n",
    "# Train and Evaluate Optimized Decision Tree Model\n",
    "print(\"\\nTraining and Evaluating Optimized Decision Tree Model:\")\n",
    "print(\"------------------------------------------------------\")\n",
    "params_dt = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search_dt = GridSearchCV(DecisionTreeClassifier(), params_dt, cv=5)\n",
    "grid_search_dt.fit(X_train, y_train)\n",
    "optimized_dt = grid_search_dt.best_estimator_\n",
    "\n",
    "# Evaluate Optimized Decision Tree Model\n",
    "y_pred_dt_optimized = optimized_dt.predict(X_test)\n",
    "optimized_dt_accuracy = accuracy_score(y_test, y_pred_dt_optimized)\n",
    "print(f\"Optimized Decision Tree Accuracy: {optimized_dt_accuracy:.4f}\")\n",
    "\n",
    "# Calculate Validation Accuracy Difference for Decision Tree\n",
    "accuracy_difference_dt = optimized_dt_accuracy - simple_lr_accuracy\n",
    "print(f\"\\nDecision Tree Validation Accuracy Difference: {accuracy_difference_dt:.4f}\")\n",
    "\n",
    "# Train and Evaluate Optimized Neural Network Model\n",
    "print(\"\\nTraining and Evaluating Optimized Neural Network Model:\")\n",
    "print(\"--------------------------------------------------------\")\n",
    "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, solver='adam', learning_rate_init=0.001, alpha=0.0001, early_stopping=True, random_state=42)\n",
    "nn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate Neural Network Model\n",
    "y_pred_nn = nn.predict(X_test)\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "\n",
    "# Calculate Validation Accuracy Difference for Neural Network\n",
    "accuracy_difference_nn = nn_accuracy - simple_lr_accuracy\n",
    "print(f\"\\nNeural Network Validation Accuracy Difference: {accuracy_difference_nn:.4f}\")\n",
    "\n",
    "# Check Consistency and Performance\n",
    "if (optimized_dt_accuracy > 0.8 and simple_lr_accuracy > 0.8 and nn_accuracy > 0.8) and (optimized_dt_accuracy > simple_lr_accuracy and nn_accuracy > simple_lr_accuracy):\n",
    "    print(\"\\nAll models show consistent results above 80%, with the optimized models outperforming the simple models.\")\n",
    "else:\n",
    "    print(\"\\nModels do not meet the specified criteria.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48cQpFlswU6r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNUBa95NK79EdAnt6FIoepb",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
